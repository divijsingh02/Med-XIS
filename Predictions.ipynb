{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "i) Paste the test images folder in the same folder consisting this code file.\n",
    "\n",
    "ii) Rename the folder to 'test'.\n",
    "\n",
    "Run the codes sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQKNSAeyN0Xe"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLfYSFTdPg0a"
   },
   "outputs": [],
   "source": [
    "# Convert the output labels to pixel-wise classes\n",
    "size=400\n",
    "def c2g(cn):\n",
    "    cn1 = np.reshape(cn, (1, 1, 3));\n",
    "    cn = cv2.cvtColor(cn1, cv2.COLOR_BGR2GRAY);\n",
    "    del cn1\n",
    "    return cn;\n",
    "\n",
    "colors = [];\n",
    "colors.append(c2g(np.array([0, 0, 0], dtype = 'uint8')));\n",
    "colors.append(c2g(np.array([255, 255, 255], dtype = 'uint8')));\n",
    "\n",
    "# colors.append(c2g(np.array([0, 0, 0], dtype = 'uint8')));\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numbers\n",
    "from abc import abstractmethod\n",
    "from typing import Tuple\n",
    "import random\n",
    "\n",
    "# print(c0)\n",
    "ClassesColors = {\n",
    "    (0,0,0): 0 ,\n",
    "     (255,255,255): 1\n",
    "            \n",
    "    }\n",
    "\n",
    "potsdam_map = {v: k for k,v in ClassesColors.items()}\n",
    "\n",
    "# \n",
    "\n",
    "def class_pixel(label_img):\n",
    "    aa,bb = label_img.shape\n",
    "\n",
    "    \n",
    "    class_pix = np.ones([aa, bb, 1], dtype = int);\n",
    "    for index, c in enumerate(colors):\n",
    "        \n",
    "        class_pix[label_img == c] = index; \n",
    "\n",
    "    \n",
    "\n",
    "    return class_pix\n",
    "def label_img_list(img_list):\n",
    "    images = [];\n",
    "    for image in img_list:\n",
    "        images.append(class_pixel(image));\n",
    "    del img_list\n",
    "    return images;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHi1BGUiIQIZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from numpy.linalg import svd\n",
    "from numpy.random import normal\n",
    "from math import sqrt\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from network.utils import IntermediateLayerGetter\n",
    "from network._deeplab import DeepLabHead, DeepLabHeadV3Plus, DeepLabV3\n",
    "from network.backbone import resnet\n",
    "from network.backbone import mobilenetv2\n",
    "\n",
    "def _segm_resnet(name, backbone_name, num_classes, output_stride, pretrained_backbone):\n",
    "\n",
    "    if output_stride==8:\n",
    "        replace_stride_with_dilation=[False, True, True]\n",
    "        aspp_dilate = [12, 24, 36]\n",
    "    else:\n",
    "        replace_stride_with_dilation=[False, False, True]\n",
    "        aspp_dilate = [6, 12, 18]\n",
    "\n",
    "    backbone = resnet.__dict__[backbone_name](\n",
    "        pretrained=pretrained_backbone,\n",
    "        replace_stride_with_dilation=replace_stride_with_dilation)\n",
    "    \n",
    "    inplanes = 2048\n",
    "    low_level_planes = 256\n",
    "\n",
    "    if name=='deeplabv3plus':\n",
    "        return_layers = {'layer4': 'out', 'layer1': 'low_level'}\n",
    "        classifier = DeepLabHeadV3Plus(inplanes, low_level_planes, num_classes, aspp_dilate)\n",
    "    elif name=='deeplabv3':\n",
    "        return_layers = {'layer4': 'out'}\n",
    "        classifier = DeepLabHead(inplanes , num_classes, aspp_dilate)\n",
    "    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
    "\n",
    "    model = DeepLabV3(backbone, classifier)\n",
    "    return model\n",
    "\n",
    "def _segm_mobilenet(name, backbone_name, num_classes, output_stride, pretrained_backbone):\n",
    "    if output_stride==8:\n",
    "        aspp_dilate = [12, 24, 36]\n",
    "    else:\n",
    "        aspp_dilate = [6, 12, 18]\n",
    "\n",
    "    backbone = mobilenetv2.mobilenet_v2(pretrained=pretrained_backbone, output_stride=output_stride)\n",
    "    \n",
    "    # rename layers\n",
    "    backbone.low_level_features = backbone.features[0:4]\n",
    "    backbone.high_level_features = backbone.features[4:-1]\n",
    "    backbone.features = None\n",
    "    backbone.classifier = None\n",
    "\n",
    "    inplanes = 320\n",
    "    low_level_planes = 24\n",
    "    \n",
    "    if name=='deeplabv3plus':\n",
    "        return_layers = {'high_level_features': 'out', 'low_level_features': 'low_level'}\n",
    "        classifier = DeepLabHeadV3Plus(inplanes, low_level_planes, num_classes, aspp_dilate)\n",
    "    elif name=='deeplabv3':\n",
    "        return_layers = {'high_level_features': 'out'}\n",
    "        classifier = DeepLabHead(inplanes , num_classes, aspp_dilate)\n",
    "    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
    "\n",
    "    model = DeepLabV3(backbone, classifier)\n",
    "    return model\n",
    "\n",
    "def _load_model(arch_type, backbone, num_classes, output_stride, pretrained_backbone):\n",
    "\n",
    "    if backbone=='mobilenetv2':\n",
    "        model = _segm_mobilenet(arch_type, backbone, num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "    elif backbone.startswith('resnet'):\n",
    "        model = _segm_resnet(arch_type, backbone, num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "    else:\n",
    "        model = _segm_resnet(arch_type, backbone, num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Deeplab v3\n",
    "\n",
    "def deeplabv3_resnet50(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-50 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3', 'resnet50', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "def deeplabv3_resnet101(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-101 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3', 'resnet101', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "def deeplabv3_mobilenet(num_classes=21, output_stride=8, pretrained_backbone=True, **kwargs):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a MobileNetv2 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3', 'mobilenetv2', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "\n",
    "# Deeplab v3+\n",
    "\n",
    "def deeplabv3plus_resnet50(num_classes=23, output_stride=2, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-50 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'resnet50', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "def deeplabv3plus_resnext50_32x4d(num_classes=2, output_stride=2, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-50 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'resnext50_32x4d', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "def deeplabv3plus_resnext101_32x8d(num_classes=2, output_stride=2, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-50 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'resnext101_32x8d', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "def deeplabv3plus_resnet101(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3+ model with a ResNet-101 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'resnet101', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "\n",
    "def deeplabv3plus_mobilenet(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3+ model with a MobileNetv2 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'mobilenetv2', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "import os\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     ntimes = 10\n",
    "#     import time\n",
    "#     import os\n",
    "#     model =  deeplabv3plus_resnet101(num_classes=2, output_stride=2, pretrained_backbone=True)\n",
    "#     model.to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         x = torch.randn(2,3,400,400)\n",
    "#         x = x.to(device)\n",
    "#         start = time.time()\n",
    "#         for i in range(ntimes):\n",
    "#             model(x)\n",
    "#         print('fps is :', 1.0/((time.time() - start)/ntimes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If testing for kvasir instrument change chal1.pth to chal2.pth\n",
    "\n",
    "If testing for kvasir seg then its set default to chal1.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAcRwE_PQJYq",
    "outputId": "2aa40fa7-73f9-4bb0-e12c-780e645c9fda"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "print(device)\n",
    "UNET = deeplabv3plus_resnet101(num_classes=2, output_stride=2, pretrained_backbone=True)\n",
    "UNET.to(device);\n",
    "\n",
    "# weightsInit(UNET)\n",
    "PATH = 'weights/chal1.pth';\n",
    "UNET.load_state_dict(torch.load(PATH))\n",
    "# !zip -r /content/file.zip /content/test_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UJZb9eCnI8M"
   },
   "outputs": [],
   "source": [
    "\n",
    "colors = [];\n",
    "colors.append(np.array([0, 0, 0], dtype = 'uint8'));\n",
    "colors.append(np.array([255, 255, 255], dtype = 'uint8'));\n",
    "\n",
    "ClassesColors = {\n",
    "    (0,0,0): 0 ,\n",
    "     (255,255,255): 1\n",
    "            \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def test(op_img):\n",
    "    class_pix = np.ones([620, 2026, 3], dtype = 'uint8');\n",
    "    for index, c in enumerate(colors):\n",
    "        class_pix[op_img == index] = c; # Vectorized masking is much much faster\n",
    "    return class_pix.reshape((620, 2026, 3))\n",
    "import numpy as np\n",
    "\n",
    "color_mapping = {\n",
    "     0 : [0,0,0], \n",
    "     1 : [255,255,255]\n",
    "}\n",
    "\n",
    "    \n",
    "semantic_map = {\n",
    "     0 : 'asphalt', \n",
    "     1 : 'gravel'\n",
    "}\n",
    "\n",
    "def visualize_prediction(prediction):\n",
    "    color_image = np.zeros((prediction.shape[0], prediction.shape[1], 3))\n",
    "    for color_id in color_mapping.keys():\n",
    "        color_image[prediction == color_id] = color_mapping[color_id]\n",
    "    return color_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "def get_class_names(class_ids):\n",
    "    return [semantic_map[i] for i in class_ids]\n",
    "def corr(x): # To get proper correspondence between the outputs and the labels\n",
    "    x = x.cpu();\n",
    "    x = x.detach().numpy(); # Detach() was used as one can't convert a pytorch tensor to a numpy array if\n",
    "    # required_grad is set True for that variable\n",
    "    x = x.argmax(axis = 1);\n",
    "    return x;\n",
    "def corrr(x): # To get proper correspondence between the outputs and the labels\n",
    "    x = x.cpu();\n",
    "    x = x.detach().numpy(); \n",
    "    return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7gHHMYhow3P"
   },
   "outputs": [],
   "source": [
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "colors = [];\n",
    "colors.append(np.array([0, 0, 0], dtype = 'uint8'));\n",
    "colors.append(np.array([255, 255, 255], dtype = 'uint8'));\n",
    "colorss=[];\n",
    "colorss.append(np.array([0, 100, 0], dtype = 'uint8'));\n",
    "colorss.append(np.array([0, 0, 255], dtype = 'uint8'));\n",
    "\n",
    "\n",
    "ClassesColors = {\n",
    "    (0,0,0): 0 ,\n",
    "     (255,255,255): 1\n",
    "            \n",
    "    }\n",
    "\n",
    "\n",
    "sen = [];\n",
    "\n",
    "def testss(img1,img2):\n",
    "    for i in range(400):\n",
    "      for j in range(400):\n",
    "        if img1[i][j]==1:\n",
    "          sen.append(np.array(img2[i][j], dtype = 'uint8'));\n",
    "    print('pass')\n",
    "    \n",
    "\n",
    "def test(op_img):\n",
    "    class_pix = np.ones([620, 2026, 3], dtype = 'uint8');\n",
    "    for index, c in enumerate(colors):\n",
    "        class_pix[op_img == index] = c; # Vectorized masking is much much faster\n",
    "    return class_pix.reshape((620, 2026, 3))\n",
    "import numpy as np\n",
    "\n",
    "color_mapping = {\n",
    "     0 : [0,0,0], \n",
    "     1 : [255,255,255]\n",
    "}\n",
    "colors_mapping = {\n",
    "     0 : [0,191,255], \n",
    "     1 : [255,0,0]\n",
    "}\n",
    "    \n",
    "semantic_map = {\n",
    "     0 : 'asphalt', \n",
    "     1 : 'gravel'}\n",
    "\n",
    "def visualize_prediction(prediction):\n",
    "    color_image = np.zeros((prediction.shape[0], prediction.shape[1], 3))\n",
    "    for color_id in color_mapping.keys():\n",
    "        color_image[prediction == color_id] = color_mapping[color_id]\n",
    "    return color_image.astype(np.uint8)\n",
    "def visualize_predictions(prediction):\n",
    "    color_image = np.zeros((prediction.shape[0], prediction.shape[1], 3))\n",
    "    for color_id in colors_mapping.keys():\n",
    "        color_image[prediction == color_id] = colors_mapping[color_id]\n",
    "    return color_image.astype(np.uint8)\n",
    "def visualize_predictionss(prediction):\n",
    "    color_image = np.zeros((prediction.shape[0], prediction.shape[1], 3))\n",
    "    for color_id in colors_mapping.keys():\n",
    "        color_image[prediction == color_id] = colors_mapping[color_id]\n",
    "    \n",
    "    return color_image.astype(np.uint8)\n",
    "\n",
    "def get_class_names(class_ids):\n",
    "    return [semantic_map[i] for i in class_ids]\n",
    "def corr(x): # To get proper correspondence between the outputs and the labels\n",
    "    x = x.cpu();\n",
    "    x = x.detach().numpy(); # Detach() was used as one can't convert a pytorch tensor to a numpy array if\n",
    "    # required_grad is set True for that variable\n",
    "    x = x.argmax(axis = 1);\n",
    "    return x;\n",
    "def class_pixel(label_img):\n",
    "    # print(label_img.shape)\n",
    "    \n",
    "    aa,bb = label_img.shape\n",
    "    \n",
    "    class_pix = np.ones([aa, bb, 1], dtype = int);\n",
    "    for index, c in enumerate(colors):\n",
    "      # class_pix[label_img ==c] = index; \n",
    "        \n",
    "        if index==0:\n",
    "          # print('index',index)\n",
    "          # print('color',c)\n",
    "\n",
    "          class_pix[label_img <=122] = index; \n",
    "        else:\n",
    "          class_pix[label_img >=123] = index; \n",
    "\n",
    "        \n",
    "\n",
    "    # print(class_pix)\n",
    "    \n",
    "\n",
    "    return class_pix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gY5bMjR5pBq0",
    "outputId": "05326dd8-5616-465d-d95c-d8c2617180ed"
   },
   "outputs": [],
   "source": [
    "# \"\"\"\"\"\"\"\" PREDICTIONS \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "def matplotlib_imshow(display_list):\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        # plt.title(title[i])\n",
    "#         print(i)\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import numpy\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "los=0\n",
    "kb=0\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "transform_img = transforms.Compose([ \n",
    "    transforms.ToTensor()]);\n",
    "# from google.colab.patches import cv2_imshow\n",
    "kb=los\n",
    "\n",
    "with torch.no_grad():\n",
    "  # model.eval()\n",
    "  c = 0;\n",
    "  folder = 'MedAI_2021_Polyp_Segmentation_Test_Dataset/'\n",
    "  images = [];\n",
    "  filenam =[];\n",
    "  submission={}\n",
    "  UNET.eval()\n",
    "  transform_img = transforms.Compose([ \n",
    "      transforms.ToTensor()]);\n",
    "  res=0\n",
    "  for name in os.listdir(folder): # List all the filenames in the folde\n",
    "      print('nwname ',name)\n",
    "      c = c + 1;\n",
    "      print(c);\n",
    "      img2 = cv2.imread(os.path.join(folder, name)); # Join the link of the folder and filename\n",
    "      # print(img.shape)\n",
    "      a1,d1,c1=img2.shape\n",
    "      \n",
    "      inputs1 = cv2.resize(img2, (400, 400))\n",
    "      img3=cv2.cvtColor(img2, cv2.COLOR_BGR2RGB);\n",
    "      \n",
    "      inputs=transform_img(inputs1)\n",
    "      inputs=inputs.unsqueeze(0).to(device)\n",
    "\n",
    "      outputs = UNET.forward(inputs);\n",
    "      \n",
    "      inputs=inputs.squeeze(0)\n",
    "      inputs= np.array(inputs.cpu())\n",
    "      inputs = inputs.reshape(size,size,3)\n",
    "      outputs = corr(outputs);\n",
    "      \n",
    "      outputs = outputs.reshape(1, size, size);\n",
    "      \n",
    "      color_pre=outputs\n",
    "      \n",
    "      dd,aa,bb = color_pre.shape\n",
    "      # d1,a1,b1 =labels[0].shape\n",
    "\n",
    "      color_pre=np.array(color_pre).reshape(aa,bb)\n",
    "\n",
    "\n",
    "      color_pre=visualize_prediction(color_pre)\n",
    "      img = cv2.resize(color_pre, (d1,a1))\n",
    "      \n",
    "      matplotlib_imshow([img3,img])\n",
    "      # print(img.shape)\n",
    "    \n",
    "      \n",
    "      cv2.imwrite('results/'+name,img)  #       CREATE THE FOLDER AND AND SAVE THE PREDICTED IMAGES IN THE FOLDER\n",
    "    \n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6NJX9fm81ba"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Predictions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
