{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:49:58.233227Z",
     "start_time": "2021-09-25T14:49:57.330592Z"
    },
    "id": "JQKNSAeyN0Xe"
   },
   "source": [
    "# Training and validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start training-\n",
    "\n",
    "i) Folders for training , training labels, validation and validation labels named as 'train', 'train_labels' , 'val' and 'val_labels' respectively should be in the same folder along with this code file\n",
    "\n",
    "ii) Network and modeling folder (as given in github) should also be in same folder\n",
    "\n",
    "Just run all the codes sequentially and you will get the output\n",
    "\n",
    "Note:\n",
    "\n",
    "i) all the images should be in .jpg \n",
    "\n",
    "ii) You can change the batch size, image resizing size (if 400 then the resized image would be 400 X 400) ,optimizer, scheduler and number of epochs in the below cell.\n",
    "\n",
    "iii) Batch size=12 and image resize=400 will cost ~10gb gpu memory and about half hour to train.\n",
    "\n",
    "iv) ideal epochs = 50 (Highest accurate model would be saved )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "\n",
    "batch     = 12\n",
    "size      = 400\n",
    "epochs    = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:49:58.424713Z",
     "start_time": "2021-09-25T14:49:58.410750Z"
    },
    "id": "aDxpUxsLPCWA"
   },
   "outputs": [],
   "source": [
    "# Import train, validation and test images from the folders and store in a list\n",
    "\n",
    "import os\n",
    "# To load images\n",
    "\n",
    "def load_img(folder):\n",
    "    c = 0;\n",
    "    images = [];\n",
    "    filenam =[];\n",
    "    for filename in os.listdir(folder): # List all the filenames in the folde\n",
    "        print('nwname ',filename)\n",
    "        c = c + 1;\n",
    "        print(c);\n",
    "        img = cv2.imread(os.path.join(folder, filename)); \n",
    "        img = cv2.resize(img, (size,size))\n",
    "        images.append(img);\n",
    "        del img\n",
    "\n",
    "    return images\n",
    "\n",
    "# To load labeled gray-scaled images\n",
    "\n",
    "def load_label_img(folder):\n",
    "    images = [];\n",
    "    c = 0;\n",
    "    for filename in os.listdir(folder): # List all the filenames in the folder\n",
    "        c = c + 1;\n",
    "        print(c);\n",
    "        img = cv2.imread(os.path.join(folder, filename));\n",
    "        img = cv2.resize(img, (size,size)) \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY);\n",
    "        # del img1\n",
    "       \n",
    "        images.append(img);\n",
    "        del img\n",
    "        \n",
    "\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:49:58.770289Z",
     "start_time": "2021-09-25T14:49:58.737378Z"
    },
    "id": "QLfYSFTdPg0a"
   },
   "outputs": [],
   "source": [
    "# Convert the output labels to pixel-wise classes\n",
    "\n",
    "def c2g(cn):\n",
    "    cn1 = np.reshape(cn, (1, 1, 3));\n",
    "    cn = cv2.cvtColor(cn1, cv2.COLOR_BGR2GRAY);\n",
    "    del cn1\n",
    "    return cn;\n",
    "\n",
    "colors = [];\n",
    "colors.append(c2g(np.array([0, 0, 0], dtype = 'uint8')));\n",
    "colors.append(c2g(np.array([255, 255, 255], dtype = 'uint8')));\n",
    "\n",
    "# colors.append(c2g(np.array([0, 0, 0], dtype = 'uint8')));\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numbers\n",
    "from abc import abstractmethod\n",
    "from typing import Tuple\n",
    "import random\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "def class_pixel(label_img):\n",
    "    # print(label_img.shape)\n",
    "    \n",
    "    aa,bb = label_img.shape\n",
    "\n",
    "    \n",
    "    class_pix = np.ones([aa, bb, 1], dtype = int);\n",
    "    for index, c in enumerate(colors):\n",
    "        \n",
    "        class_pix[label_img == c] = index; \n",
    "    # print(class_pix)\n",
    "    \n",
    "\n",
    "    return class_pix\n",
    "def label_img_list(img_list):\n",
    "    images = [];\n",
    "    for image in img_list:\n",
    "        images.append(class_pixel(image));\n",
    "    del img_list\n",
    "    return images;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:50:00.274274Z",
     "start_time": "2021-09-25T14:49:59.083385Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUs-7cbAClIu",
    "outputId": "a5f1cb90-46e7-4fab-8b59-74642a07b22d"
   },
   "outputs": [],
   "source": [
    "# FOR VALIDATION\n",
    "\n",
    "import os\n",
    "\n",
    "# To load images\n",
    "\n",
    "def loads_img(folder):\n",
    "    c = 0;\n",
    "    images = [];\n",
    "    filenam =[];\n",
    "    for filename in os.listdir(folder): # List all the filenames in the folde\n",
    "        print('nwname ',filename)\n",
    "        c = c + 1;\n",
    "        print(c);\n",
    "        img = cv2.imread(os.path.join(folder, filename)); \n",
    "        img = cv2.resize(img, (size,size))\n",
    "        images.append(img);\n",
    "        # if c==16:\n",
    "          # break\n",
    "        del img\n",
    "\n",
    "    return images\n",
    "\n",
    "# To load labeled gray-scaled images\n",
    "\n",
    "def loads_label_img(folder):\n",
    "    images = [];\n",
    "    c = 0;\n",
    "    for filename in os.listdir(folder): # List all the filenames in the folder\n",
    "        c = c + 1;\n",
    "        # print(c);\n",
    "        img = cv2.imread(os.path.join(folder, filename));\n",
    "       \n",
    "        images.append(img);\n",
    "        # if c==14:\n",
    "        #   break\n",
    "        del img\n",
    "        \n",
    "\n",
    "\n",
    "    return images\n",
    "\n",
    "def matplotlib_imshow(display_list):\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        # plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "transform_img = transforms.Compose([ \n",
    "    transforms.ToTensor()]);\n",
    "    \n",
    "\n",
    "transform_img_label = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]);\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "    \n",
    "class testsett(data.Dataset):\n",
    "    def __init__(self, transform = None, root_test = None, root_test_label = None, transform_label = None):\n",
    "        self.test_img= loads_img(root_test);\n",
    "        self.transform = transform;\n",
    "        # self.transform_label = transform_label;\n",
    "        self.test_label_img = loads_label_img(root_test_label);\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_img);\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.transform(self.test_img[index]);\n",
    "        label = self.test_label_img[index];\n",
    "        # name = self.name[index]\n",
    "\n",
    "\n",
    "        return img, label;\n",
    "\n",
    "\n",
    "testdatasets = testsett(transform_img, 'val', 'val_labels', transform_img_label);\n",
    "\n",
    "val_loader = data.DataLoader(testdatasets, batch_size = 1, shuffle=False,  num_workers=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:50:19.813239Z",
     "start_time": "2021-09-25T14:50:00.339103Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHRJG3PHPrAF",
    "outputId": "ac6b95ae-682b-4db6-f19e-163848b29733"
   },
   "outputs": [],
   "source": [
    "# Define the transformations that have to be applied on the images\n",
    "def matplotlib_imshow(display_list):\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "transform_img = transforms.Compose([ \n",
    "    transforms.ToTensor()]);\n",
    "    \n",
    "\n",
    "transform_img_label = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]);\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# We have to create custom classes in order to use the DataLoader. These classes inherit the Dataset class\n",
    "\n",
    "class trainset(data.Dataset):\n",
    "    def __init__(self, transform = None, root_train = None, root_train_label = None, transform_label = None):\n",
    "        self.train_img = load_img(root_train);\n",
    "        self.transform = transform;\n",
    "        self.transform_label = transform_label;\n",
    "        self.train_label_img = label_img_list(load_label_img(root_train_label));\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.train_img);\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.transform(self.train_img[index]);\n",
    "        label = self.transform_label(self.train_label_img[index]);\n",
    "        # print(index)\n",
    "        return img, label;\n",
    "\n",
    "class valset(data.Dataset):\n",
    "    def __init__(self, transform = None, root_val = None, root_val_label = None, transform_label = None):\n",
    "        self.val_img = load_img(root_val);\n",
    "        self.transform = transform;\n",
    "        self.transform_label = transform_label;\n",
    "        self.val_label_img = label_img_list(load_label_img(root_val_label));\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.val_img);\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.transform(self.val_img[index]);\n",
    "        label = self.transform_label(self.val_label_img[index]);\n",
    "        \n",
    "\n",
    "        return img, label;\n",
    "\n",
    "    \n",
    "class testset(data.Dataset):\n",
    "    def __init__(self, transform = None, root_test = None, root_test_label = None, transform_label = None):\n",
    "        self.test_img= load_img(root_test);\n",
    "        self.transform = transform;\n",
    "        self.transform_label = transform_label;\n",
    "        self.test_label_img = label_img_list(load_label_img(root_test_label));\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_img);\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.transform(self.test_img[index]);\n",
    "        label = self.transform_label(self.test_label_img[index]);\n",
    "        # name = self.name[index]\n",
    "\n",
    "\n",
    "        return img, label;\n",
    "\n",
    "\n",
    "traindataset = trainset(transform_img, 'train', 'train_labels', transform_img_label);\n",
    "train_loader = data.DataLoader(traindataset, batch_size = batch, shuffle=True,  num_workers=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:50:20.067574Z",
     "start_time": "2021-09-25T14:50:20.037652Z"
    },
    "id": "mHi1BGUiIQIZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from numpy.linalg import svd\n",
    "from numpy.random import normal\n",
    "from math import sqrt\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from network.utils import IntermediateLayerGetter\n",
    "from network._deeplab import DeepLabHead, DeepLabHeadV3Plus, DeepLabV3\n",
    "from network.backbone import resnet\n",
    "from network.backbone import mobilenetv2\n",
    "\n",
    "def _segm_resnet(name, backbone_name, num_classes, output_stride, pretrained_backbone):\n",
    "\n",
    "    if output_stride==8:\n",
    "        replace_stride_with_dilation=[False, True, True]\n",
    "        aspp_dilate = [12, 24, 36]\n",
    "    else:\n",
    "        replace_stride_with_dilation=[False, False, True]\n",
    "        aspp_dilate = [6, 12, 18]\n",
    "\n",
    "    backbone = resnet.__dict__[backbone_name](\n",
    "        pretrained=pretrained_backbone,\n",
    "        replace_stride_with_dilation=replace_stride_with_dilation)\n",
    "    \n",
    "    inplanes = 2048\n",
    "    low_level_planes = 256\n",
    "\n",
    "    if name=='deeplabv3plus':\n",
    "        return_layers = {'layer4': 'out', 'layer1': 'low_level'}\n",
    "        classifier = DeepLabHeadV3Plus(inplanes, low_level_planes, num_classes, aspp_dilate)\n",
    "    elif name=='deeplabv3':\n",
    "        return_layers = {'layer4': 'out'}\n",
    "        classifier = DeepLabHead(inplanes , num_classes, aspp_dilate)\n",
    "    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
    "\n",
    "    model = DeepLabV3(backbone, classifier)\n",
    "    return model\n",
    "\n",
    "def _segm_mobilenet(name, backbone_name, num_classes, output_stride, pretrained_backbone):\n",
    "    if output_stride==8:\n",
    "        aspp_dilate = [12, 24, 36]\n",
    "    else:\n",
    "        aspp_dilate = [6, 12, 18]\n",
    "\n",
    "    backbone = mobilenetv2.mobilenet_v2(pretrained=pretrained_backbone, output_stride=output_stride)\n",
    "    \n",
    "    # rename layers\n",
    "    backbone.low_level_features = backbone.features[0:4]\n",
    "    backbone.high_level_features = backbone.features[4:-1]\n",
    "    backbone.features = None\n",
    "    backbone.classifier = None\n",
    "\n",
    "    inplanes = 320\n",
    "    low_level_planes = 24\n",
    "    \n",
    "    if name=='deeplabv3plus':\n",
    "        return_layers = {'high_level_features': 'out', 'low_level_features': 'low_level'}\n",
    "        classifier = DeepLabHeadV3Plus(inplanes, low_level_planes, num_classes, aspp_dilate)\n",
    "    elif name=='deeplabv3':\n",
    "        return_layers = {'high_level_features': 'out'}\n",
    "        classifier = DeepLabHead(inplanes , num_classes, aspp_dilate)\n",
    "    backbone = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
    "\n",
    "    model = DeepLabV3(backbone, classifier)\n",
    "    return model\n",
    "\n",
    "def _load_model(arch_type, backbone, num_classes, output_stride, pretrained_backbone):\n",
    "\n",
    "    if backbone=='mobilenetv2':\n",
    "        model = _segm_mobilenet(arch_type, backbone, num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "    elif backbone.startswith('resnet'):\n",
    "        model = _segm_resnet(arch_type, backbone, num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return model\n",
    "\n",
    "\n",
    "# Deeplab v3\n",
    "\n",
    "def deeplabv3_resnet50(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-50 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3', 'resnet50', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "def deeplabv3_resnet101(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-101 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3', 'resnet101', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "def deeplabv3_mobilenet(num_classes=21, output_stride=8, pretrained_backbone=True, **kwargs):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a MobileNetv2 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3', 'mobilenetv2', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "\n",
    "# Deeplab v3+\n",
    "\n",
    "def deeplabv3plus_resnet50(num_classes=23, output_stride=2, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3 model with a ResNet-50 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'resnet50', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "\n",
    "def deeplabv3plus_resnet101(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3+ model with a ResNet-101 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'resnet101', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n",
    "\n",
    "\n",
    "def deeplabv3plus_mobilenet(num_classes=21, output_stride=8, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV3+ model with a MobileNetv2 backbone.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        output_stride (int): output stride for deeplab.\n",
    "        pretrained_backbone (bool): If True, use the pretrained backbone.\n",
    "    \"\"\"\n",
    "    return _load_model('deeplabv3plus', 'mobilenetv2', num_classes, output_stride=output_stride, pretrained_backbone=pretrained_backbone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:50:23.561335Z",
     "start_time": "2021-09-25T14:50:20.131879Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAcRwE_PQJYq",
    "outputId": "26acd2a8-ecea-4b5a-be02-92397b1e1717"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "print(device)\n",
    "UNET = deeplabv3plus_resnet101(num_classes=2, output_stride=2, pretrained_backbone=True)\n",
    "UNET.to(device);\n",
    "\n",
    "# weightsInit(UNET)\n",
    "PATH = 'weights/chal2.pth';\n",
    "UNET.load_state_dict(torch.load(PATH))\n",
    "# !zip -r /content/file.zip /content/test_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:50:23.671040Z",
     "start_time": "2021-09-25T14:50:23.657078Z"
    },
    "id": "4UJZb9eCnI8M"
   },
   "outputs": [],
   "source": [
    "colors = [];\n",
    "colors.append(np.array([0, 0, 0], dtype = 'uint8'));\n",
    "colors.append(np.array([255, 255, 255], dtype = 'uint8'));\n",
    "\n",
    "ClassesColors = {\n",
    "    (0,0,0): 0 ,\n",
    "     (255,255,255): 1\n",
    "            \n",
    "    }\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "color_mapping = {\n",
    "     0 : [0,0,0], \n",
    "     1 : [255,255,255]\n",
    "}\n",
    "    \n",
    "\n",
    "def visualize_prediction(prediction):\n",
    "    color_image = np.zeros((prediction.shape[0], prediction.shape[1], 3))\n",
    "    for color_id in color_mapping.keys():\n",
    "        color_image[prediction == color_id] = color_mapping[color_id]\n",
    "    return color_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "def corr(x): # To get proper correspondence between the outputs and the labels\n",
    "    x = x.cpu();\n",
    "    x = x.detach().numpy(); # Detach() was used as one can't convert a pytorch tensor to a numpy array if\n",
    "    # required_grad is set True for that variable\n",
    "    x = x.argmax(axis = 1);\n",
    "    return x;\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "color_mapping = {\n",
    "     0 : [0,0,0], \n",
    "     1 : [255,255,255]\n",
    "}\n",
    "\n",
    "    \n",
    "def class_pixel(label_img):\n",
    "    aa,bb = label_img.shape\n",
    "    \n",
    "    class_pix = np.ones([aa, bb, 1], dtype = int);\n",
    "    for index, c in enumerate(colors):\n",
    "        \n",
    "        if index==0:\n",
    "          class_pix[label_img <=122] = index; \n",
    "        else:\n",
    "          class_pix[label_img >=123] = index; \n",
    "    return class_pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:50:23.765002Z",
     "start_time": "2021-09-25T14:50:23.750826Z"
    },
    "id": "ZDBnT5Z2QTwP"
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:50:23.875237Z",
     "start_time": "2021-09-25T14:50:23.847464Z"
    },
    "id": "c7gHHMYhow3P"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device);\n",
    "optimizer = optim.Adam(UNET.parameters(),lr=0.0001 );\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:10:04.413042Z",
     "start_time": "2021-09-25T14:09:21.291786Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5tg5vqBQa3p",
    "outputId": "f938d9dd-c3ab-416b-ca49-c4320ff238d8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1\n",
    "los=0\n",
    "kb=0\n",
    "km=1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "init=85\n",
    "UNET.train()\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  print('epoch-                ',epoch)\n",
    "  print('prev loss-            ',(kb/6000)*batch)\n",
    "  print('final loss-           ',(los/6000)*batch)\n",
    "  kb=los\n",
    "  los=0\n",
    "  UNET.train()\n",
    "  for i, data in enumerate(train_loader):\n",
    "    inputs, labels = data;\n",
    "    \n",
    "    labels = labels.reshape(batch, size, size);\n",
    "    \n",
    "    inputs, labels = inputs.to(device), labels.to(device);\n",
    "    optimizer.zero_grad();\n",
    "    \n",
    "    output1 = UNET(inputs);\n",
    "    labels = labels.to(dtype=torch.long)\n",
    "\n",
    "    loss1 = criterion(output1, labels);\n",
    "    loss1.backward();\n",
    "    optimizer.step();\n",
    "    los+=loss1.item()\n",
    "    \n",
    "    if i%60==59:\n",
    "\n",
    "      with torch.no_grad():\n",
    "        correct = 0;\n",
    "        total = 0;\n",
    "        UNET.eval()\n",
    "        import cv2\n",
    "        def _fast_hist(label_pred, label_true, n_class):\n",
    "            mask = (label_true >= 0) & (label_true < n_class)\n",
    "            hist = np.bincount(\n",
    "                n_class * label_true[mask].astype(int) + label_pred[mask], minlength=n_class ** 2\n",
    "            ).reshape(n_class, n_class)\n",
    "            return hist\n",
    "\n",
    "\n",
    "        def evaluate(predictions, gts, num_classes):\n",
    "            hist = np.zeros((num_classes, num_classes))\n",
    "            for lp, lt in zip(predictions, gts):\n",
    "                hist += _fast_hist(lp.flatten(), lt.flatten(), num_classes)\n",
    "            \n",
    "            iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "            mean_iu = np.nanmean(iu)\n",
    "            \n",
    "            return mean_iu\n",
    "\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, labels = data;\n",
    "            inputs = inputs.to(device);\n",
    "\n",
    "            outputs = UNET.forward(inputs);\n",
    "            outputs = corr(outputs);\n",
    "            labels = labels.detach().numpy();\n",
    "            outputs = outputs.reshape(1, size, size);\n",
    "            correct=correct+1\n",
    "\n",
    "            color_pred=labels[0]\n",
    "            d1,a1,b1 =labels[0].shape\n",
    "            \n",
    "            color_pre=outputs\n",
    "            \n",
    "            dd,aa,bb = color_pre.shape\n",
    "            d1,a1,b1 =labels[0].shape\n",
    "\n",
    "            color_pre=np.array(color_pre).reshape(aa,bb)\n",
    "\n",
    "\n",
    "            color_pre=visualize_prediction(color_pre)\n",
    "            img = cv2.resize(color_pre, (a1,d1))\n",
    "            \n",
    "            img1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY);\n",
    "            img2 = cv2.cvtColor(color_pred, cv2.COLOR_BGR2GRAY);\n",
    "            img1 = class_pixel(img1)\n",
    "            img2 = class_pixel(img2)\n",
    "            \n",
    "            io=evaluate(img1,img2,2)\n",
    "            total=total+io\n",
    "\n",
    "        print(\"Hence, the test set accuracy is \", (total/correct) * 100);\n",
    "        if (total/correct) * 100>init:\n",
    "          init=(total/correct) * 100\n",
    "          PATH = 'pathmax101res.pth';\n",
    "          torch.save(UNET.state_dict(),PATH); \n",
    "        print(\"Highest accuracy :\",init)        \n",
    "    \n",
    "\n",
    "\n",
    "        UNET.train()\n",
    "\n",
    "  scheduler.step()\n",
    "  print('Epoch    -    {0}    lr    :     {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "  if epoch%1==0:\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "      correct = 0;\n",
    "      total = 0;\n",
    "      UNET.eval()\n",
    "      import cv2\n",
    "      def _fast_hist(label_pred, label_true, n_class):\n",
    "          mask = (label_true >= 0) & (label_true < n_class)\n",
    "          hist = np.bincount(\n",
    "              n_class * label_true[mask].astype(int) + label_pred[mask], minlength=n_class ** 2\n",
    "          ).reshape(n_class, n_class)\n",
    "          return hist\n",
    "\n",
    "\n",
    "      def evaluate(predictions, gts, num_classes):\n",
    "          hist = np.zeros((num_classes, num_classes))\n",
    "          for lp, lt in zip(predictions, gts):\n",
    "              hist += _fast_hist(lp.flatten(), lt.flatten(), num_classes)\n",
    "          \n",
    "          iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "          mean_iu = np.nanmean(iu)\n",
    "          \n",
    "          return mean_iu\n",
    "\n",
    "      for i, data in enumerate(val_loader):\n",
    "          inputs, labels = data;\n",
    "          inputs = inputs.to(device);\n",
    "\n",
    "          outputs = UNET.forward(inputs);\n",
    "          outputs = corr(outputs);\n",
    "          labels = labels.detach().numpy();\n",
    "          outputs = outputs.reshape(1, size, size);\n",
    "          correct=correct+1\n",
    "\n",
    "          color_pred=labels[0]\n",
    "          d1,a1,b1 =labels[0].shape\n",
    "          color_pre=outputs\n",
    "          # print('shape ',color_pre.shape)\n",
    "          dd,aa,bb = color_pre.shape\n",
    "          d1,a1,b1 =labels[0].shape\n",
    "\n",
    "          color_pre=np.array(color_pre).reshape(aa,bb)\n",
    "\n",
    "\n",
    "          color_pre=visualize_prediction(color_pre)\n",
    "          img = cv2.resize(color_pre, (a1,d1))\n",
    "          \n",
    "          img1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY);\n",
    "          img2 = cv2.cvtColor(color_pred, cv2.COLOR_BGR2GRAY);\n",
    "          img1 = class_pixel(img1)\n",
    "          img2 = class_pixel(img2)\n",
    "\n",
    "          io=evaluate(img1,img2,2)\n",
    "          total=total+io\n",
    "\n",
    "      print(\"Hence, the test set accuracy is \", (total/correct) * 100);\n",
    "      if (total/correct) * 100>init:\n",
    "          init=(total/correct) * 100\n",
    "          PATH = 'pathmax101res.pth';\n",
    "          torch.save(UNET.state_dict(),PATH); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:55:06.527795Z",
     "start_time": "2021-09-25T14:55:06.474909Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def class_pixel(label_img):\n",
    "    # print(label_img.shape)\n",
    "    \n",
    "    aa,bb = label_img.shape\n",
    "    \n",
    "    class_pix = np.ones([aa, bb, 1], dtype = int);\n",
    "    for index, c in enumerate(colors):\n",
    "        if index==0:\n",
    "          class_pix[label_img <=122] = index; \n",
    "        else:\n",
    "          class_pix[label_img >=123] = index; \n",
    "    return class_pix\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "__all__ = ['SegmentationMetric']\n",
    "\n",
    "\"\"\"\n",
    "confusionMetric  # 注意：此处横着代表预测值，竖着代表真实值，与之前介绍的相反\n",
    "P\\L     P    N\n",
    "P      TP    FP\n",
    "N      FN    TN\n",
    "sum(axis=0) TP+FN\n",
    "sum(axis=1) TP+FP\n",
    "np.diag().sum() TP+TN\n",
    "\"\"\"\n",
    "class SegmentationMetric(object):\n",
    "    def __init__(self, numClass):\n",
    "        self.numClass = numClass\n",
    "        self.confusionMatrix = np.zeros((self.numClass,)*2)\n",
    "\n",
    "    def pixelAccuracy(self):\n",
    "        # return all class overall pixel accuracy\n",
    "        #  PA = acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        acc = np.diag(self.confusionMatrix).sum() /  self.confusionMatrix.sum()\n",
    "        return acc\n",
    "\n",
    "    def meanPixelAccuracy(self):\n",
    "        # return each category pixel accuracy(A more accurate way to call it precision)\n",
    "        # acc = TP / (TP + FP)\n",
    "        Cpa = np.diag(self.confusionMatrix) / self.confusionMatrix.sum(axis=1)\n",
    "        Mpa = np.nanmean(Cpa)  \n",
    "        return Mpa, Cpa\n",
    "\n",
    "\n",
    "    def meanIntersectionOverUnion(self):\n",
    "        # Intersection = TP ;Union = TP + FP + FN\n",
    "        # Ciou = TP / (TP + FP + FN)\n",
    "        intersection = np.diag(self.confusionMatrix)\n",
    "        union = np.sum(self.confusionMatrix, axis=1) + np.sum(self.confusionMatrix, axis=0) - np.diag(self.confusionMatrix) # axis = 1表示混淆矩阵行的值，返回列表； axis = 0表示取混淆矩阵列的值，返回列表\n",
    "\n",
    "        Ciou = (intersection / np.maximum(1.0, union))   \n",
    "        mIoU = np.nanmean(Ciou)  \n",
    "        return mIoU, Ciou\n",
    "\n",
    "    def Frequency_Weighted_Intersection_over_Union(self):\n",
    "        # FWIOU =     [(TP+FN)/(TP+FP+TN+FN)] *[TP / (TP + FP + FN)]\n",
    "        freq = np.sum(self.confusionMatrix, axis=1) / np.sum(self.confusionMatrix)\n",
    "        iu = np.diag(self.confusionMatrix) / (\n",
    "                np.sum(self.confusionMatrix, axis=1) + np.sum(self.confusionMatrix, axis=0) -\n",
    "                np.diag(self.confusionMatrix))\n",
    "        FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "        return FWIoU\n",
    "\n",
    "    def precision(self):\n",
    "        # precision = TP / (TP+FP)\n",
    "        precision = np.diag(self.confusionMatrix) / np.sum(self.confusionMatrix, axis=1)\n",
    "        return precision\n",
    "\n",
    "    def recall(self):\n",
    "        # recall = TP / (TP+FN)\n",
    "        recall = np.diag(self.confusionMatrix) / np.sum(self.confusionMatrix, axis=0)\n",
    "        return recall\n",
    "\n",
    "    def genConfusionMatrix(self, imgPredict, imgLabel):\n",
    "        # remove classes from unlabeled pixels in gt image and predict\n",
    "        mask = (imgLabel >= 0) & (imgLabel < self.numClass)\n",
    "        label = self.numClass * imgLabel[mask].astype('int') + imgPredict[mask]\n",
    "        count = np.bincount(label, minlength=self.numClass**2)\n",
    "        confusionMatrix = count.reshape(self.numClass, self.numClass)\n",
    "        return confusionMatrix\n",
    "\n",
    "    def addBatch(self, imgPredict, imgLabel):\n",
    "        assert imgPredict.shape == imgLabel.shape\n",
    "        self.confusionMatrix += self.genConfusionMatrix(imgPredict, imgLabel)\n",
    "\n",
    "    def reset(self):\n",
    "        self.confusionMatrix = np.zeros((self.numClass, self.numClass))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    imgPredict = np.array([0, 0, 0, 0])\n",
    "    imgLabel = np.array([0, 0, 0, 0]) \n",
    "    metric = SegmentationMetric(2) \n",
    "    metric.addBatch(imgPredict, imgLabel)\n",
    "    pa = metric.pixelAccuracy()\n",
    "    cpa = metric.recall()[0]\n",
    "    pre = metric.precision()[0]\n",
    "    mpa = metric.meanPixelAccuracy()\n",
    "    mIoU, per = metric.meanIntersectionOverUnion()\n",
    "\n",
    "EPS = 1e-10\n",
    "def nanmean(x):\n",
    "    \"\"\"Computes the arithmetic mean ignoring any NaNs.\"\"\"\n",
    "    return torch.mean(x[x == x])\n",
    "def _fast_hist(true, pred, num_classes):\n",
    "    mask = (true >= 0) & (true < num_classes)\n",
    "    hist = torch.bincount(\n",
    "        num_classes * true[mask] + pred[mask],\n",
    "        minlength=num_classes ** 2,\n",
    "    ).reshape(num_classes, num_classes).float()\n",
    "    return hist\n",
    "def dice_coefficient(hist):\n",
    "    \"\"\"Computes the Sørensen–Dice coefficient, a.k.a the F1 score.\n",
    "    Args:\n",
    "        hist: confusion matrix.\n",
    "    Returns:\n",
    "        avg_dice: the average per-class dice coefficient.\n",
    "    \"\"\"\n",
    "    A_inter_B = torch.diag(hist)\n",
    "    A = hist.sum(dim=1)\n",
    "    B = hist.sum(dim=0)\n",
    "    dice = (2 * A_inter_B) / (A + B + EPS)\n",
    "    avg_dice = nanmean(dice)\n",
    "    return avg_dice\n",
    "\n",
    "\n",
    "def eval_metrics(true, pred, num_classes):\n",
    "    \"\"\"Computes various segmentation metrics on 2D feature maps.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, H, W] or [B, 1, H, W].\n",
    "        pred: a tensor of shape [B, H, W] or [B, 1, H, W].\n",
    "        num_classes: the number of classes to segment. This number\n",
    "            should be less than the ID of the ignored class.\n",
    "    Returns:\n",
    "        overall_acc: the overall pixel accuracy.\n",
    "        avg_per_class_acc: the average per-class pixel accuracy.\n",
    "        avg_jacc: the jaccard index.\n",
    "        avg_dice: the dice coefficient.\n",
    "    \"\"\"\n",
    "    hist = torch.zeros((num_classes, num_classes))\n",
    "    for t, p in zip(true, pred):\n",
    "        hist += _fast_hist(t.flatten(), p.flatten(), num_classes)\n",
    "    \n",
    "    avg_dice = dice_coefficient(hist)\n",
    "    return avg_dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-25T14:58:46.080425Z",
     "start_time": "2021-09-25T14:58:15.359056Z"
    }
   },
   "outputs": [],
   "source": [
    "# PATH = 'pathmax101res.pth'\n",
    "# UNET.load_state_dict(torch.load(PATH))   \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "def matplotlib_imshow(display_list):\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import numpy\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "los=0\n",
    "kb=0\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "transform_img = transforms.Compose([ \n",
    "    transforms.ToTensor()]);\n",
    "# from google.colab.patches import cv2_imshow\n",
    "kb=los\n",
    "los=0\n",
    "fs=0\n",
    "p=0\n",
    "pre=0\n",
    "rec=0\n",
    "di=0\n",
    "with torch.no_grad():\n",
    "  correct = 0;\n",
    "  total = 0;\n",
    "  UNET.eval()\n",
    "  import cv2\n",
    "  def _fast_hist(label_pred, label_true, n_class):\n",
    "      mask = (label_true >= 0) & (label_true < n_class)\n",
    "      hist = np.bincount(\n",
    "          n_class * label_true[mask].astype(int) + label_pred[mask], minlength=n_class ** 2\n",
    "      ).reshape(n_class, n_class)\n",
    "      return hist\n",
    "\n",
    "\n",
    "  def evaluate(predictions, gts, num_classes):\n",
    "      hist = np.zeros((num_classes, num_classes))\n",
    "      for lp, lt in zip(predictions, gts):\n",
    "          hist += _fast_hist(lp.flatten(), lt.flatten(), num_classes)\n",
    "      \n",
    "      iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "      mean_iu = np.nanmean(iu)\n",
    "      \n",
    "      return mean_iu\n",
    "\n",
    "  for i, data in enumerate(val_loader):\n",
    "      print('  ',i)\n",
    "      inputs, labels = data;\n",
    "      inputs = inputs.to(device);\n",
    "\n",
    "      outputs= UNET.forward(inputs);\n",
    "      \n",
    "      inputs=inputs.squeeze(0)\n",
    "      inputs= np.array(inputs.cpu())\n",
    "      inputs = inputs.reshape(size,size,3)\n",
    "      outputs = corr(outputs);\n",
    "      labels = labels.detach().numpy();\n",
    "      outputs = outputs.reshape(1, size, size);\n",
    "      correct=correct+1\n",
    "\n",
    "      color_pred=labels[0]\n",
    "      d1,a1,b1 =labels[0].shape\n",
    "      \n",
    "      color_pre=outputs\n",
    "      \n",
    "      dd,aa,bb = color_pre.shape\n",
    "      d1,a1,b1 =labels[0].shape\n",
    "\n",
    "      color_pre=np.array(color_pre).reshape(aa,bb)\n",
    "\n",
    "\n",
    "      color_pre=visualize_prediction(color_pre)\n",
    "      img = cv2.resize(color_pre, (a1,d1))\n",
    "      inputs = cv2.resize(inputs, (a1,d1))\n",
    "      inputs=inputs\n",
    "      color_preds=copy.deepcopy(color_pred)\n",
    "      \n",
    "\n",
    "\n",
    "      img1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY);\n",
    "      img2 = cv2.cvtColor(color_preds, cv2.COLOR_BGR2GRAY);\n",
    "      img1 = class_pixel(img1)\n",
    "      img2 = class_pixel(img2)\n",
    "      \n",
    "      io=evaluate(img1,img2,2)\n",
    "      matplotlib_imshow([color_pred,img])\n",
    "      cv2.imwrite('result/'+'genintru'+'.jpg',img)\n",
    "      cv2.imwrite('result/'+'gtintru'+'.jpg',color_pred)\n",
    "      total=total+io\n",
    "      metric = SegmentationMetric(2) \n",
    "      metric.addBatch(img1, img2)\n",
    "      pa = metric.pixelAccuracy()\n",
    "      \n",
    "      cpa = metric.recall()[0]\n",
    "      prec = metric.precision()[0]\n",
    "\n",
    "      # mpa = metric.meanPixelAccuracy()\n",
    "      mIoU,per= metric.meanIntersectionOverUnion()\n",
    "      print('   pixel acc is : %f' % pa)\n",
    "      \n",
    "      print('   mIoU is : %f' % mIoU)\n",
    "      print('   mIoU (2nd code) is : %f' % io)\n",
    "      print('   recall: ',cpa)\n",
    "      print('   precision: ',prec)\n",
    "      ff= (5 * prec * cpa) / (4 * prec + cpa)\n",
    "      print('   F2 score: ',ff)\n",
    "      pre=pre+cpa\n",
    "      p=p+pa\n",
    "      rec=rec+prec\n",
    "      fs=fs+ff\n",
    "      dice=eval_metrics(img1, img2, 2)\n",
    "      print('dice coeff: ',dice)\n",
    "      di=di+dice.item()\n",
    "     \n",
    "print(\" \")\n",
    "print(\" \")      \n",
    "print(\"Final test results\")\n",
    "print(\" \")\n",
    "print(\"mIoU score \", (total/correct) * 100);\n",
    "print('f2 score: ',(fs/correct)*100)\n",
    "print('recall : ',(pre/correct) * 100)\n",
    "print('dice coefficient: ',(di/correct) * 100)\n",
    "print('precision : ',(rec/correct) * 100)\n",
    "\n",
    "print('pixel accuracy : ',(p/correct) * 100)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "challenge 2",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
